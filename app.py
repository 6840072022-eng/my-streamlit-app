import streamlit as st
import pandas as pd
import requests
from bs4 import BeautifulSoup
import json
import time
import base64

# -----------------------------
#  CONFIG
# -----------------------------

API_BASE = "https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key="


# -----------------------------
#  CORE FUNCTIONS
# -----------------------------

def call_gemini(system_prompt, user_prompt, api_key):
    """‡πÄ‡∏£‡∏µ‡∏¢‡∏Å Google Gemini API"""
    if not api_key:
        return None  # ‡πÑ‡∏°‡πà‡πÄ‡∏£‡∏µ‡∏¢‡∏Å API ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ñ‡∏µ‡∏¢‡πå

    try:
        payload = {
            "system_instruction": {"parts": [{"text": system_prompt}]},
            "contents": [{"parts": [{"text": user_prompt}]}],
        }

        url = API_BASE + api_key
        response = requests.post(url, json=payload)
        response.raise_for_status()

        data = response.json()
        return data["candidates"][0]["content"]["parts"][0]["text"]

    except Exception as e:
        st.error(f"‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á‡πÄ‡∏£‡∏µ‡∏¢‡∏Å Gemini API: {e}")
        return None


def extract_article(url):
    """‡∏î‡∏∂‡∏á‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏à‡∏≤‡∏Å‡πÄ‡∏ß‡πá‡∏ö‡πÑ‡∏ã‡∏ï‡πå"""
    try:
        headers = {"User-Agent": "Mozilla/5.0"}
        r = requests.get(url, headers=headers, timeout=10)
        r.raise_for_status()

        soup = BeautifulSoup(r.text, "html.parser")
        for tag in ["script", "style", "header", "footer", "nav", "img"]:
            for x in soup.find_all(tag):
                x.decompose()

        article = soup.find("article") or soup.find("main") or soup.find("body")
        text = "\n".join([p.get_text().strip() for p in article.find_all("p")])

        title = soup.title.string if soup.title else url

        return title, text

    except Exception as e:
        return None, f"‚ùå ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏î‡∏∂‡∏á‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡πÑ‡∏î‡πâ: {e}"


def df_download(df, filename):
    """‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏õ‡∏∏‡πà‡∏°‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î CSV"""
    csv = df.to_csv(index=False).encode()
    b64 = base64.b64encode(csv).decode()
    href = f'<a href="data:file/csv;base64,{b64}" download="{filename}">‚¨áÔ∏è ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î CSV</a>'
    st.markdown(href, unsafe_allow_html=True)


# -----------------------------
#       MAIN APP UI
# -----------------------------

def main():
    st.set_page_config(page_title="NLP App (LLM)", layout="wide")
    st.title("üìò NLP Web App with Google Gemini")

    # Sidebar
    with st.sidebar:
        st.header("üîë API Settings")
        api_key = st.text_input("Gemini API Key (optional)", type="password")
        st.caption("‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏Å‡∏£‡∏≠‡∏Å ‚Üí ‡∏£‡∏∞‡∏ö‡∏ö‡∏à‡∏∞‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡πÅ‡∏ö‡∏ö‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πâ LLM ‡πÑ‡∏î‡πâ‡∏ï‡∏≤‡∏°‡∏õ‡∏Å‡∏ï‡∏¥")

        st.markdown("---")
        st.header("üìù ‡∏ß‡∏¥‡∏ò‡∏µ‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô")
        st.write(
            """
            ‚úî ‡∏õ‡πâ‡∏≠‡∏ô URL ‡∏´‡∏£‡∏∑‡∏≠‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå CSV/Excel  
            ‚úî ‡∏ñ‡πâ‡∏≤‡πÉ‡∏™‡πà API Key ‚Üí ‡πÄ‡∏õ‡∏¥‡∏î‡πÇ‡∏´‡∏°‡∏î LLM (Summarization, Entity Extraction, etc.)
            ‚úî ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡πÉ‡∏™‡πà ‚Üí ‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏Å‡∏≤‡∏£‡∏î‡∏∂‡∏á‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡πÑ‡∏î‡πâ
        """
        )

    # Tabs
    tab1, tab2 = st.tabs(["üåç ‡∏≠‡πà‡∏≤‡∏ô‡∏à‡∏≤‡∏Å URL", "üìÅ ‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î CSV/Excel"])

    article_text = None
    article_title = None

    # ---------------------------
    # OPTION 1 ‚Äî URL
    # ---------------------------
    with tab1:
        url = st.text_input("‡πÉ‡∏™‡πà URL ‡∏ö‡∏ó‡∏Ñ‡∏ß‡∏≤‡∏°")
        if st.button("‡∏î‡∏∂‡∏á‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤"):
            title, text = extract_article(url)
            if text:
                article_title = title
                article_text = text
                st.success(f"üìå ‡∏î‡∏∂‡∏á‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡πÑ‡∏î‡πâ: {title}")
                st.code(text[:1000] + "..." if len(text) > 1000 else text)

    # ---------------------------
    # OPTION 2 ‚Äî CSV / Excel
    # ---------------------------
    with tab2:
        file = st.file_uploader("‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î CSV ‡∏´‡∏£‡∏∑‡∏≠ Excel", type=["csv", "xlsx"])
        if file:
            df = pd.read_csv(file) if file.name.endswith(".csv") else pd.read_excel(file)
            st.dataframe(df, use_container_width=True)
            article_text = "\n".join(df.iloc[:, 0].astype(str).tolist())
            article_title = "‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå"

    # ---------------------------
    #  NLP TASKS (‡πÉ‡∏ä‡πâ LLM)
    # ---------------------------
    if article_text:

        st.markdown("---")
        st.header("‚ú® NLP Tasks")

        if not api_key:
            st.warning("‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏û‡∏ö API Key ‚Äî ‡πÇ‡∏´‡∏°‡∏î LLM ‡∏ñ‡∏π‡∏Å‡∏õ‡∏¥‡∏î\n‡πÅ‡∏ï‡πà‡∏Ñ‡∏∏‡∏ì‡∏¢‡∏±‡∏á‡∏≠‡πà‡∏≤‡∏ô‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡πÑ‡∏î‡πâ‡∏ï‡∏≤‡∏°‡∏õ‡∏Å‡∏ï‡∏¥")
            return

        # -------- Task 1 Summary -------
        st.subheader("üìù Task 1 ‚Äî Summarization")
        system_1 = "‡∏Ñ‡∏∏‡∏ì‡πÄ‡∏õ‡πá‡∏ô‡∏ú‡∏π‡πâ‡πÄ‡∏ä‡∏µ‡πà‡∏¢‡∏ß‡∏ä‡∏≤‡∏ç‡∏î‡πâ‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡∏™‡∏£‡∏∏‡∏õ‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤ ‡πÉ‡∏´‡πâ‡∏™‡∏£‡∏∏‡∏õ‡∏ö‡∏ó‡∏Ñ‡∏ß‡∏≤‡∏°‡πÉ‡∏´‡πâ‡∏≠‡πà‡∏≤‡∏ô‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡∏á‡πà‡∏≤‡∏¢‡πÉ‡∏ô 5‚Äì10 ‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ"
        output_1 = call_gemini(system_1, article_text, api_key)
        if output_1:
            st.write(output_1)

        # -------- Task 2 Entity Extraction -------
        st.subheader("üß© Task 2 ‚Äî Entity Extraction (JSON)")
        system_2 = """
            ‡∏Ñ‡∏∏‡∏ì‡πÄ‡∏õ‡πá‡∏ô NLP Model ‡πÉ‡∏´‡πâ‡∏î‡∏∂‡∏á Entities ‡∏´‡∏•‡∏±‡∏Å‡πÉ‡∏ô‡∏ö‡∏ó‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ô‡∏µ‡πâ:
            - Person
            - Organization
            - Location
            - Date
            ‡πÅ‡∏•‡∏∞‡∏ï‡∏≠‡∏ö‡∏Å‡∏•‡∏±‡∏ö‡πÄ‡∏õ‡πá‡∏ô JSON array ‡πÄ‡∏ä‡πà‡∏ô:
            [{"entity":"Google","type":"Organization"}]
        """
        json_text = call_gemini(system_2, article_text, api_key)
        try:
            df_entities = pd.DataFrame(json.loads(json_text))
            st.dataframe(df_entities)
            df_download(df_entities, "entities.csv")
        except:
            st.error("‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô JSON ‡πÑ‡∏î‡πâ")

        # -------- Task 3 Sentiment -------
        st.subheader("üòä Task 3 ‚Äî Deep Sentiment Analysis")
        system_3 = """
            ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå‡πÄ‡∏ä‡∏¥‡∏á‡∏•‡∏∂‡∏Å‡∏Ç‡∏≠‡∏á‡∏ö‡∏ó‡∏Ñ‡∏ß‡∏≤‡∏°‡πÉ‡∏´‡πâ‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡∏°‡∏≤‡∏Å:
            - ‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå‡∏´‡∏•‡∏±‡∏Å (Primary Emotion)
            - ‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå‡∏£‡∏≠‡∏á (Secondary Emotion)
            - ‡πÅ‡∏£‡∏á‡∏à‡∏π‡∏á‡πÉ‡∏à‡∏Ç‡∏≠‡∏á‡∏ú‡∏π‡πâ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô
            - ‡∏ô‡πâ‡∏≥‡πÄ‡∏™‡∏µ‡∏¢‡∏á (Tone)
            - ‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô Sentiment (-5 = ‡∏•‡∏ö‡∏°‡∏≤‡∏Å, 5 = ‡∏ö‡∏ß‡∏Å‡∏°‡∏≤‡∏Å)
        """
        output_3 = call_gemini(system_3, article_text, api_key)
        if output_3:
            st.write(output_3)


if __name__ == "__main__":
    main()
